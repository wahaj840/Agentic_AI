# ğŸ§  Agentic AI â€“ Week 1 Progress Report  
**Goal:** Complete the environment setup, connect LLM providers, and push a clean, secure codebase to GitHub.  

---

## ğŸ“… Duration  
**Day 1 â€” Environment Setup & Verification**

---

## âš™ï¸ 1ï¸âƒ£ Setup Summary  

| Task | Description | Status |
|------|--------------|--------|
| Python Environment | Created and activated a virtual environment (`python â€“m venv .venv`) | âœ… |
| Dependency Setup | Verified pip, planned to add `requirements.txt` later | âœ… |
| Environment Variables | Created `.env.example` and `.env` for API keys | âœ… |
| Git Configuration | Added `.gitignore` for `.env`, `.venv`, and cache files | âœ… |
| GitHub Repo | Connected via `gh auth login` | âœ… |
| Push Protection Fix | Removed exposed secrets and rebuilt commit history | âœ… |
| Provider Check | Verified Groq / Hugging Face / Ollama | âœ… |
| Agent Test | Successfully ran prompts (`Say hello`, `Weather in Dublin`) | âœ… |

---

## ğŸ§© 2ï¸âƒ£ Difficulties Faced & Solutions  

| Issue | Description | Root Cause | Solution |
|-------|--------------|------------|-----------|
| **1. PowerShell Script Activation Blocked** | Error: â€œRunning scripts is disabled on this systemâ€ when executing `.\.venv\Scripts\Activate.ps1` | Default PowerShell execution policy restricted script loading | Executed: `Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass` |
| **2. GitHub Push Rejected â€“ Secrets Detected** | Push blocked due to Groq API key detected in `.env.example` | GitHub push protection blocked commit history containing sensitive keys | Removed secrets and rebuilt branch via:<br>`git checkout --orphan clean-main` â†’ `git add .` â†’ `git push --force` |
| **3. GH CLI Login Token Error** | â€œMissing required scope â€˜read:orgâ€™â€ during authentication | Incomplete OAuth permissions | Re-authenticated using `gh auth login` â†’ selected â€œLogin with web browserâ€ |
| **4. Python File Not Found** | Running `python check_env.py` returned â€œNo such file or directoryâ€ | Script was executed from the wrong directory | Navigated to correct path using `cd week_1` |
| **5. API Key Not Found** | `check_env.py` displayed â€œAPI key not foundâ€ | `.env` file not yet created locally | Duplicated `.env.example` â†’ renamed to `.env` â†’ added keys locally |
| **6. CLI Ampersand Error** | â€œ& operator is not allowedâ€ in PowerShell | PowerShell interpreted `&` as a command operator | Removed the `&` character or enclosed commands in double quotes |
| **7. Push Protection Cache Residuals** | GitHub still rejected push after removing key | Old commit history still contained key traces | Cleaned repo via:<br>`git reflog expire --expire=now --all` â†’ `git gc --prune=now --aggressive` |
| **8. Provider Verification Failed** | Initial run didnâ€™t detect Groq or HF | `.env` not loaded properly | Fixed with `dotenv` check in `check_env.py` |
| **9. Invalid CLI Argument** | â€œunrecognized arguments: --providerâ€ | `argparse` implementation incomplete | Updated `agent_test.py` with correct argument parser |

---

## ğŸ“˜ 3ï¸âƒ£ Key Learnings  

- Understood **how GitHub Push Protection** detects and blocks secrets.  
- Learned to **clean commit history safely** using orphan branches.  
- Gained clarity on **environment variable management** with `.env` and `.env.example`.  
- Configured **PowerShell execution policies** for virtual environments.  
- Successfully integrated and verified **Groq, Hugging Face, and Ollama providers**.  
- Confirmed **LLM agent response flow** through CLI commands.  

---

## ğŸ§ª 4ï¸âƒ£ Verification Results  


# Environment check
python check_env.py
âœ… GROQ_API_KEY found  
âœ… HF_TOKEN found  
âœ… OLLAMA_HOST set â†’ http://localhost:11434  
ğŸ‰ At least one provider is configured.

# Agent test
python agent_test.py --prompt "What's the weather in Dublin today?"
--- Used provider: GROQ ---
(Produces detailed natural language response)
---




## ğŸš€ Day 2: Agent Architecture & Prompt Chaining

### ğŸ¯ Objective
Implement a multi-step **agent pipeline** capable of decomposing a high-level goal into structured subtasks, executing them sequentially with LLM reasoning, and synthesizing all results into a final actionable plan.

---

### ğŸ§  Key Tasks Completed
1. **Created `agent_chain.py`** â€“ the main agent logic file.  
2. Implemented a **3-stage reasoning workflow**:
   - **Plan:** break a complex user goal into multiple actionable subtasks.  
   - **Execute:** process each subtask independently via the chosen LLM provider (Groq â†’ Hugging Face â†’ Ollama fallback).  
   - **Synthesize:** merge all intermediate results into a coherent final report.  
3. Integrated **multi-provider routing** with automatic fallback based on environment variables (`.env`).  
4. Validated the full pipeline using the test prompt:  
   > `"Design a lead-qualifier AI micro-SaaS for small e-commerce stores"`  
5. Observed correct subtask generation, independent reasoning per step, and a final synthesized business plan output.

---

### âš™ï¸ Technical Outcomes
| Feature | Description | Status |
|----------|--------------|--------|
| Multi-provider routing | Groq â†’ HF â†’ Ollama fallback | âœ… |
| Modular design | Functions: `plan_task`, `execute_subtasks`, `synthesize_output` | âœ… |
| CLI Integration | Accepts `--prompt` argument for dynamic queries | âœ… |
| Output Trace | Displays reasoning flow and subtask logs in terminal | âœ… |
| Final Output | Structured and contextualized synthesis report | âœ… |

---

### ğŸ§© Example Run
```bash
python agent_chain.py --prompt "Design a lead-qualifier AI micro-SaaS for small e-commerce stores"


--- Used provider: GROQ ---
ğŸ“‹ PLAN:
  1. Conduct market research to identify target audience needs and pain points.
  2. Define the key features for the AI-powered lead qualifier.
  3. Design a user-friendly interface.
  4. Develop a machine learning model.
  5. Plan the technical infrastructure for deployment and scalability.

âš™ï¸ Subtask 1: Conduct market research...
âš™ï¸ Subtask 2: Define key features...
...
ğŸ§© SYNTHESIS:
âœ… Final summarized business plan generated successfully!


---

## ğŸš€ Day 3: Tool Integration & Smart Routing

### ğŸ¯ Objective
Expand the agentâ€™s capabilities by integrating **external tools** (Search / Math / File Writer) and enabling it to **decide automatically** whether to call a tool or perform reasoning through the existing chain.

---

### âš™ï¸ Key Tasks Completed

| Task | Description | Status |
|------|--------------|--------|
| **Tool Detection Logic** | Implemented `looks_like_tool_request()` to auto-detect when a prompt requires a tool (e.g. "search", "save", math expressions). | âœ… |
| **Tool Router (`use_tools`)** | Added central router to delegate queries to `search_web`, `solve_math`, or `write_to_file`. | âœ… |
| **Math Tool** | Performs safe calculations (e.g. `23 * 7 + 12 â†’ 173`). | âœ… |
| **Search Tool** | Simulates web search results (`[Tool: Search] Simulated web searchâ€¦`). | âœ… |
| **File Writer Tool** | Saves generated content to `outputs/agent_output.txt` with success confirmation. | âœ… |
| **Argument Parser Update** | Added `--prompt` (required) and `--act` (optional) flags to `main()`. | âœ… |
| **Smart Router Decision Flow** | Routes to either tool mode or reasoning chain based on prompt. | âœ… |
| **Full System Validation** | Successfully tested end-to-end scenarios for Reasoning and Tool modes. | âœ… |

---

### ğŸ§ª Verification Results

```bash
# Reasoning chain
python agent_chain.py --prompt "Design a lead-qualifier AI micro-SaaS for small e-commerce stores"
# âœ… Produced multi-step plan, executed subtasks, and merged final report.

# Web search (tool mode)
python agent_chain.py --prompt "search latest AI tools 2025"
# â†’ [Tool: Search] Simulated web search results for 'latest AI tools 2025'

# Math (tool mode)
python agent_chain.py --prompt "23 * 7 + 12"
# â†’ The result of 23 * 7 + 12 is 173

# File write (tool mode)
python agent_chain.py --prompt "save this summary"
# â†’ [Tool: File Writer] Content saved successfully â†’ outputs\agent_output.txt

# Force tool mode
python agent_chain.py --act --prompt "search Mistral vs Llama benchmarks"
# â†’ [Tool: Search] Simulated web search results for 'Mistral vs Llama benchmarks'
